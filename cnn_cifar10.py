# -*- coding: utf-8 -*-
"""cnn_cifar10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k36nVVAEFkXqoiKndoqdYdx70PgWnN-U
"""

"""
参照: https://github.com/AtaruOhto/lecture_pytorch/blob/master/lecture4/cnn.ipynb

CIFAR10 Convolutional Neural Network
"""

from torchvision.datasets import CIFAR10
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt

# CIFAR10のデータをダウンロード
cifar10_data = CIFAR10(root="./data",train=False,download=True,transform=transforms.ToTensor())
print("CIFAR10のデータの数:", len(cifar10_data))

# CIFAR10のクラス分類を定義
cifar10_classes = np.array(["airplane", "automobile", "bird", "cat", "deer","dog", "frog", "horse", "ship", "truck"])

# 表示する画像の数
n_image = 25

# 画像の表示サイズを設定 縦・横10
plt.figure(figsize=(10,10))  

# データをDataLoader形式に変換する。
cifar10_loader = DataLoader(cifar10_data, batch_size=n_image, shuffle=True)

# https://github.com/pytorch/pytorch/issues/1917#issuecomment-311163345
# データローダーから最初のバッチを取り出す
images, labels =  (iter(cifar10_loader)).next() 

# 取り出したバッチをループ
for i in range(n_image):
    # plt.subplot(図を5行に分割、図を5列に分割、左上から数えてi + 1番目のプロット)
    plt.subplot(5, 5, i+1)
    
    # データの軸を入れ替えて、画像のチャンネルを一番後ろに持ってくる (画像を表示するため)
    # 画像のデータ形式: torch.Size([3, 32, 32]) => torch.Size([32, 32, 3])
    plt.imshow(np.transpose(images[i], (1, 2, 0)))

    # ラベルを表示
    label = cifar10_classes[labels[i]]
    plt.title(label)

    # 目盛りを非表示にする
    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  

plt.show()

from torchvision.datasets import CIFAR10
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt

# データ拡張 (Data Augmentationを実行する) = 過学習対策
# https://qiita.com/hoshiryu/items/f84d253b79184c903c27 (PyTorchでデータ拡張(Data Augmentation)を比較してみる)
transform = transforms.Compose(
  [
   transforms.RandomAffine(
       # 画像を-30度～30度の間で回転させる
       [-30, 30], 
       # 画像を 0.8 〜 1.2の間でスケーリングさせる
       scale=(0.8, 1.2)
       ),  
    transforms.ToTensor()
  ]
)

# CIFAR10のデータにデータ拡張を施す (transform=transform)
cifar10_data = CIFAR10(root="./data", train=False,download=True, transform=transform)

# 以下は上のコードセルと同じ処理をする。データ拡張 (Data Augumentation) された画像が表示される。
cifar10_loader = DataLoader(cifar10_data, batch_size=n_image, shuffle=True)
plt.figure(figsize=(10,10))
images, labels = (iter(cifar10_loader)).next()
for i in range(n_image):
    plt.subplot(5, 5, i+1)
    plt.imshow(np.transpose(images[i], (1, 2, 0))) 
    label = cifar10_classes[labels[i]]
    plt.title(label)
    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False) 

plt.show()

from torchvision.datasets import CIFAR10
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# 画像に回転と拡大・縮小処理をかける。
affine = transforms.RandomAffine([-15, 15], scale=(0.8, 1.2)) 

# https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomHorizontalFlip
# 50%の確率で画像を左右反転させる。
flip = transforms.RandomHorizontalFlip(p=0.5) 

# データの正規化をする (平均値を0、標準偏差を1に)
normalize = transforms.Normalize((0.0, 0.0, 0.0), (1.0, 1.0, 1.0))

# Converts a PIL Image or numpy.ndarray to a torch.FloatTensor of shape (C x H x W)
to_tensor = transforms.ToTensor()

# 訓練用データ用の変換形式のセット
transform_train = transforms.Compose([affine, flip, to_tensor, normalize])

# 訓練用データ用の変換形式のセット
transform_test = transforms.Compose([to_tensor, normalize])

# 上記で定義した変換形式のセットをかけて、訓練用データと検証用データを用意する
cifar10_train = CIFAR10("./data", train=True, download=True, transform=transform_train)
cifar10_test = CIFAR10("./data", train=False, download=True, transform=transform_test)

# DataLoaderの設定
batch_size = 64
train_loader = DataLoader(cifar10_train, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(cifar10_test, batch_size=len(cifar10_test), shuffle=False)

import torch.nn as nn
import torch.nn.functional as F

# CNN ニューラルネットワークを定義する
class Net(nn.Module):
    def __init__(self):
        super().__init__()
        # 畳み込み層1 :(入力チャンネル数, フィルタ数、フィルタサイズ)
        self.conv1 = nn.Conv2d(3, 6, 5)

        # 畳み込み層2 :(入力チャンネル数, フィルタ数、フィルタサイズ)
        self.conv2 = nn.Conv2d(6, 16, 5)

        # マックスプーリングを実施: （領域のサイズ, ストライド）
        self.pool = nn.MaxPool2d(2, 2) 

        # チャンネル数が16で5×5の画像が入力の全結合層
        self.fc1 = nn.Linear(16*5*5, 256) 

        # ドロップアウト:(p=ドロップアウト率) 
        self.dropout = nn.Dropout(p=0.5)
        self.fc2 = nn.Linear(256, 10)

    def forward(self, x):
        # 1: torch.Size([64, 3, 32, 32]) 画像のデータ形式
        x = self.conv1(x)
        # 2: torch.Size([64, 6, 28, 28])
        x = F.relu(x)
        # 3: torch.Size([64, 6, 28, 28])
        x = self.pool(x)
        # 4: torch.Size([64, 6, 14, 14])
        x = self.conv2(x)
        # 5: torch.Size([64, 16, 10, 10])
        x = F.relu(x)
        # 6: torch.Size([64, 16, 10, 10])
        x = self.pool(x)
        # 7: torch.Size([64, 16, 5, 5])
        x = x.view(-1, 16*5*5)
        # 8: torch.Size([64, 400])
        x = self.fc1(x)
        # 9 torch.Size([64, 256])
        x = F.relu(x)
        # 10: torch.Size([64, 256])
        x = self.dropout(x)
        # 画像は10種類あるので、10で出力する。
        x = self.fc2(x)
        return x

net = Net()
net.cuda()  # GPU対応
print(net)

from torch import optim

# 交差エントロピー誤差関数
loss_fnc = nn.CrossEntropyLoss()

# 最適化アルゴリズム
optimizer = optim.Adam(net.parameters())

# 損失のログ
record_loss_train = []
record_loss_test = []

# 学習
x_test, t_test = iter(test_loader).next()
x_test, t_test = x_test.cuda(), t_test.cuda()

# 20エポックで学習
for i in range(20):  
    # 訓練モード
    net.train()  
    loss_train = 0

    # ミニバッチ（x, t）を取り出す
    for j, (x, t) in enumerate(train_loader):
        # GPU対応
        x, t = x.cuda(), t.cuda()
        y = net(x)
        loss = loss_fnc(y, t)

        # 損失を記録
        loss_train += loss.item()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    loss_train /= j+1
    record_loss_train.append(loss_train)

    # 評価モード (ドロップアウトなどは実行しない)
    net.eval()  
    y_test = net(x_test)
    loss_test = loss_fnc(y_test, t_test).item()
    record_loss_test.append(loss_test)

    if i % 1 == 0:
        print("Epoch:", i, "Loss_Train:", loss_train, "Loss_Test:", loss_test)

import matplotlib.pyplot as plt

plt.plot(range(len(record_loss_train)), record_loss_train, label="Train")
plt.plot(range(len(record_loss_test)), record_loss_test, label="Test")
plt.legend()

plt.xlabel("Epochs")
plt.ylabel("Error")
plt.show()

correct = 0
total = 0
net.eval()  # 評価モード
for i, (x, t) in enumerate(test_loader):
    x, t = x.cuda(), t.cuda()  # GPU対応
    y = net(x)
    correct += (y.argmax(1) == t).sum().item()
    total += len(x)
print(f"正解率: {correct / total * 100}%")

cifar10_loader = DataLoader(cifar10_test, batch_size=1, shuffle=True)
dataiter = iter(cifar10_loader)
images, labels = dataiter.next()  # サンプルを1つだけ取り出す

plt.imshow(np.transpose(images[0], (1, 2, 0)))  # チャンネルを一番後ろに
plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # ラベルとメモリを非表示に
plt.show()

net.eval()  # 評価モード
x, t = images.cuda(), labels.cuda()  # GPU対応
y = net(x)
print("正解:", cifar10_classes[labels[0]],
      "予測結果:", cifar10_classes[y.argmax().item()])