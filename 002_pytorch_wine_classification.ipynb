{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "002_pytorch_wine_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/UZlqI831jf9PVQGE5SdK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtaruOhto/pytorch_learning/blob/master/002_pytorch_wine_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkbsS2UP1jTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e1a833b6-140d-468e-d089-0a2839e26583"
      },
      "source": [
        "\"\"\"\n",
        "PyTorch でワインの種類を分類\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# sklearnからワインのデータをロードする\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "Y = wine.target\n",
        "\n",
        "feature_num = X.shape[1]\n",
        "classification_num = len(np.unique(Y))\n",
        "\n",
        "# データ情報を表示\n",
        "pd.DataFrame(wine.data, columns=wine.feature_names)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  ...   hue  od280/od315_of_diluted_wines  proline\n",
              "0      14.23        1.71  2.43  ...  1.04                          3.92   1065.0\n",
              "1      13.20        1.78  2.14  ...  1.05                          3.40   1050.0\n",
              "2      13.16        2.36  2.67  ...  1.03                          3.17   1185.0\n",
              "3      14.37        1.95  2.50  ...  0.86                          3.45   1480.0\n",
              "4      13.24        2.59  2.87  ...  1.04                          2.93    735.0\n",
              "..       ...         ...   ...  ...   ...                           ...      ...\n",
              "173    13.71        5.65  2.45  ...  0.64                          1.74    740.0\n",
              "174    13.40        3.91  2.48  ...  0.70                          1.56    750.0\n",
              "175    13.27        4.28  2.26  ...  0.59                          1.56    835.0\n",
              "176    13.17        2.59  2.37  ...  0.60                          1.62    840.0\n",
              "177    14.13        4.10  2.74  ...  0.61                          1.60    560.0\n",
              "\n",
              "[178 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLYlCrSg1jpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "2cae857f-887a-4f65-f9e7-148268933935"
      },
      "source": [
        "# 25%を検証用データとして用いる\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.25)\n",
        "\n",
        "train_X = torch.from_numpy(train_X).float()\n",
        "train_Y = torch.from_numpy(train_Y).long()\n",
        "test_X = torch.from_numpy(test_X).float()\n",
        "test_Y = torch.from_numpy(test_Y).long()\n",
        "\n",
        "# 訓練データをTensorDatasetで一組にする。\n",
        "train = TensorDataset(train_X, train_Y)\n",
        "\n",
        "# ミニバッチ学習させるために、DataLoader形式に変換する。\n",
        "train_loader = DataLoader(train, batch_size=15, shuffle=True)\n",
        "\n",
        "# ニューラルネットワークの定義\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    unit_num = 128\n",
        "    self.fc1 = nn.Linear(feature_num, unit_num)\n",
        "    self.fc2 = nn.Linear(unit_num, unit_num)\n",
        "    self.fc3 = nn.Linear(unit_num, unit_num)\n",
        "    self.fc4 = nn.Linear(unit_num, unit_num)\n",
        "    self.fc5 = nn.Linear(unit_num, unit_num)\n",
        "    self.fc6 = nn.Linear(unit_num, classification_num)\n",
        "    \n",
        "  def forward(self, x):    \n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = F.relu(self.fc4(x))\n",
        "    x = F.relu(self.fc5(x))\n",
        "    x = self.fc6(x)\n",
        "    return F.log_softmax(x)\n",
        "\n",
        "model = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(1500):\n",
        "  total_loss = 0\n",
        "\n",
        "  for train_x, train_y in train_loader:\n",
        "    train_x, train_y = Variable(train_x), Variable(train_y)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(train_x)\n",
        "    loss = criterion(output, train_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.data.item()\n",
        "\n",
        "  if(epoch + 1) % 100 == 0:\n",
        "    print(f\" {epoch + 1}回目の誤差: \", total_loss / epoch)\n",
        "\n",
        "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
        "result = torch.max(model(test_x).data, 1)[1]\n",
        "\n",
        "\n",
        "accuracy_score = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
        "print(\"正解率: \", accuracy_score)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 100回目の誤差:  0.0619730521934201\n",
            " 200回目の誤差:  0.028378667244360077\n",
            " 300回目の誤差:  0.016684813244286986\n",
            " 400回目の誤差:  0.011972468598444658\n",
            " 500回目の誤差:  0.011224347986056952\n",
            " 600回目の誤差:  0.008968536563230078\n",
            " 700回目の誤差:  0.006783580106385958\n",
            " 800回目の誤差:  0.0058534816373722424\n",
            " 900回目の誤差:  0.005532102205596856\n",
            " 1000回目の誤差:  0.004385185671282244\n",
            " 1100回目の誤差:  0.004699669012272759\n",
            " 1200回目の誤差:  0.004127086401979957\n",
            " 1300回目の誤差:  0.0037213277367099235\n",
            " 1400回目の誤差:  0.00301238208519211\n",
            " 1500回目の誤差:  0.003506938742350705\n",
            "正解率:  0.6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}